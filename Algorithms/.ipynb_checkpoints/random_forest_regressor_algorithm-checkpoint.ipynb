{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd13141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt      \n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing, linear_model, model_selection\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import r2_score, f1_score \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c41b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomForestRegressor() \n",
    "\n",
    "def load_dataset(df, label_column):\n",
    "    y = df[label_column]\n",
    "    X = df.drop(label_column, axis=1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def data_split(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def normalize_data(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def train_model(X_train_scaled, y_train):\n",
    "    forest = RandomForestRegressor(max_depth=5, min_samples_split=2 ,n_estimators=100)\n",
    "    forest.fit(X_train_scaled, y_train)\n",
    "    return forest\n",
    "\n",
    "def predict_model(X_test_scaled,y_test , forest):\n",
    "    y_pred = forest.predict(X_test_scaled)\n",
    "    result = pd.DataFrame({'Actual': y_test, 'Predicted':  np.round(y_pred)})\n",
    "    result['difference'] =  result[\"Actual\"] -  result[\"Predicted\"] \n",
    "    print(f\"Forest Score {forest.score(X_test_scaled,y_test)}\")\n",
    "\n",
    "    return y_pred, result\n",
    "\n",
    " \n",
    "def evaluate_model(y_test, y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, r2\n",
    "\n",
    "def tune_model(X_train_scaled, y_train):\n",
    "    params = {'max_depth': [5, 10, 15], 'n_estimators': [50, 100, 200], 'min_samples_split': [2, 4, 6] }\n",
    "    grid_search_cv = GridSearchCV(RandomForestRegressor(), params, n_jobs=-1, verbose=1, cv=7)\n",
    "    grid_search_cv.fit(X_train_scaled, y_train)\n",
    "    best_params = grid_search_cv.best_params_\n",
    "    best_score = grid_search_cv.best_score_\n",
    "    print(grid_search_cv.best_estimator_)\n",
    "    return best_params, best_score\n",
    "\n",
    "def return_best_model(X_train_scaled, X_test_scaled, y_train, y_test, best_params):\n",
    "    reg = RandomForestRegressor(**best_params)\n",
    "    reg.fit(X_train_scaled, y_train)\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "    return reg, y_pred\n",
    "\n",
    "\n",
    "def Remove_outliers(df):\n",
    "    for col in df.select_dtypes(include=['float64','int']).columns:\n",
    "        q1, q3 = np.percentile(df[col], [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 -(1.5 * iqr) \n",
    "        upper_bound = q3 +(1.5 * iqr)\n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "    return df\n",
    "\n",
    "def drop_non_numeric_and_na_cols(df):\n",
    "    # Get the list of non-numeric columns\n",
    "    df = df.dropna(subset=['Long','Lat','Rooms','Floor','Floors']).reset_index(drop=True)\n",
    "    non_numeric_cols = list(df.select_dtypes(exclude=['number']).columns)\n",
    "    \n",
    "    # Get the list of columns that contain NaNs\n",
    "    na_cols = list(df.columns[df.isna().any()])\n",
    "    \n",
    "    # Combine the two lists and drop the columns from the DataFrame\n",
    "    cols_to_drop = list(set(non_numeric_cols) | set(na_cols))\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73362d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50593, 15)\n",
      "Forest Score 0.18128212451158\n",
      "Fitting 7 folds for each of 27 candidates, totalling 189 fits\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../Data/Real_Estate_TLV_Numric_Data.csv\",index_col=0)\n",
    "# df.drop(['AVG_SALARY'],axis =1 , inplace =True)\n",
    "df = pd.read_csv(\"../Data/Nadlan_clean.csv\",index_col=0)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y')\n",
    "df['Year'] = df['Date'].dt.strftime('%Y')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# df.drop(['NEIGHBORHOOD'],axis =1 , inplace =True)\n",
    "\n",
    "df = df[df['Year'] < 2023]\n",
    "df = df[df['Year'] > 2003]\n",
    "\n",
    "df['AVG_ROOM_SIZE'] = (df[\"Size\"] / df['Rooms']).round(1)\n",
    "\n",
    "df = drop_non_numeric_and_na_cols(df)\n",
    "\n",
    "\n",
    "df = Remove_outliers(df)\n",
    "\n",
    "print(df.shape)\n",
    "label_column = \"Price\"\n",
    "\n",
    "X , y = load_dataset(df,label_column)\n",
    "X_train, X_test, y_train, y_test = data_split(X, y)\n",
    "\n",
    "\n",
    "#2. Normalize Data\n",
    "X_train_scaled, X_test_scaled = normalize_data(X_train, X_test)\n",
    "\n",
    "#3. Train Model\n",
    "forest = train_model(X_train_scaled, y_train)\n",
    "\n",
    "#4. Predict Model\n",
    "y_pred , result = predict_model(X_test_scaled,y_test, forest)\n",
    "\n",
    "#5. Evaluate Model\n",
    "mae, r2 = evaluate_model(y_test, y_pred)\n",
    "\n",
    "#6. Tune Model\n",
    "best_params, best_score = tune_model(X_train_scaled, y_train)\n",
    "\n",
    "#7. Return Best Model\n",
    "forest, y_pred = return_best_model(X_train_scaled, X_test_scaled, y_train, y_test, best_params)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"MAE:\", mae) # mae = mean_absolute_error\n",
    "print(\"R2:\", r2)\n",
    "X_train.hist()\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(X_train.corr(), annot =True ,cmap ='YlGnBu')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yad2_df = pd.read_csv(\"../Data/Real_Estate_TLV_YAD2_Numeric.csv\",index_col=0)\n",
    "yad2_df.drop(['neighborhood'],axis =1 , inplace =True)\n",
    "yad2_df['year'] = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rename_yad2_df(df):\n",
    "    df.rename(columns={'price':'DEALAMOUNT'}, inplace=True)\n",
    "#     df.rename(columns={'neighborhood':'NEIGHBORHOOD'}, inplace=True)\n",
    "    df.rename(columns={'buildingMR':'ASSETMETER'}, inplace=True)\n",
    "    df.rename(columns={'TotalFloors':'BUILDINGFLOORS'}, inplace=True)\n",
    "    df.rename(columns={'floor':'FLOOR'}, inplace=True)\n",
    "    df.rename(columns={'buildyear':'BUILDINGYEAR'}, inplace=True)\n",
    "    df.rename(columns={'year':'DATE'}, inplace=True)\n",
    "    df.rename(columns={'rooms':'ROOMNUM'}, inplace=True)\n",
    "#     df = df.reindex(columns=[\"DATE\", \"DEALAMOUNT\", \"BUILDINGYEAR\", \"BUILDINGYEAR\", \"BUILDINGFLOORS\",\n",
    "#                               \"NEIGHBORHOOD\", \"ROOMNUM\", \"FLOOR\", \"ASSETMETER\", \"long\", \"lat\", \"Distance_From_Sea\"])\n",
    "    return df\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    df.drop(['parking', 'balconies','shelter','on_pillars','storeroom','asset_classification','elevator','home_number'], axis=1 , inplace=True )\n",
    "#     df['AVG_ROOM_SIZE'] = (df[\"buildingMR\"] / df['rooms']).round(1)\n",
    "    df = rename_yad2_df(df)\n",
    "    \n",
    "    df['BUILDINGFLOORS'] = df['BUILDINGFLOORS'].astype(int)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Remove columns with only one unique value\n",
    "#     unique_counts = df.nunique()\n",
    "#     cols_to_drop = unique_counts[unique_counts == 1].index\n",
    "#     df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    # Remove outliers\n",
    "    for col in df.select_dtypes(include=['float64','int']).columns:\n",
    "        q1, q3 = np.percentile(df[col], [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 -(1.5 * iqr) \n",
    "        upper_bound = q3 +(1.5 * iqr)\n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def recommend_affordable_apartments(df, model):\n",
    "    # Normalize the data\n",
    "    X, y = load_dataset(df, \"DEALAMOUNT\")\n",
    "    \n",
    "    # We dont need the the second params so we will call it '_'\n",
    "    X_scaled, _ = normalize_data(X, X)\n",
    "    \n",
    "    \n",
    "    # Predict prices using the trained model\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    y_pred = y_pred * 1.28 # 0.22 % is the percentage of increase in the last year (2022)\n",
    "    df[\"PREDICTED_PRICE\"] = y_pred\n",
    "    df[\"PREDICTED_PRICE\"] = df[\"PREDICTED_PRICE\"].astype(int)\n",
    "    df['difference'] =  df[\"DEALAMOUNT\"] -  df[\"PREDICTED_PRICE\"] \n",
    "    \n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    print(f'r2_score: {r2} , mae: {mae}')\n",
    "\n",
    "    return df.sort_values(by=\"difference\")\n",
    "\n",
    "yad2_df = preprocess_dataframe(yad2_df)\n",
    "yad2_df = yad2_df.reindex(columns=[\"DATE\", \"DEALAMOUNT\", \"BUILDINGYEAR\", \"BUILDINGFLOORS\",\n",
    "                               \"ROOMNUM\", \"FLOOR\", \"ASSETMETER\", \"long\", \"lat\", \"Distance_From_Sea\"]) #\"NEIGHBORHOOD\",\n",
    "\n",
    "yad2_df = yad2_df[np.isfinite(yad2_df[\"ASSETMETER\"] / yad2_df['ROOMNUM'])]\n",
    "yad2_df['AVG_ROOM_SIZE'] = (yad2_df[\"ASSETMETER\"] / yad2_df['ROOMNUM']).round(1)\n",
    "yad2_df['AVG_ROOM_SIZE'] = yad2_df['AVG_ROOM_SIZE'].astype(int)\n",
    "\n",
    "affordable_deals = recommend_affordable_apartments(yad2_df, forest)\n",
    "affordable_deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affordable_deals = recommend_affordable_apartments(yad2_df, forest)\n",
    "# affordable_deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "affordable_deals.sort_values(by=\"difference\",  ascending=True )\n",
    "\n",
    "affordable_deals = affordable_deals.reindex(columns=[\"DATE\", \"DEALAMOUNT\",'PREDICTED_PRICE','difference', \"BUILDINGYEAR\", \"BUILDINGFLOORS\",\n",
    "                               \"ROOMNUM\", \"FLOOR\", \"ASSETMETER\", \"long\", \"lat\", \"Distance_From_Sea\"])\n",
    "#NEIGHBORHOOD\n",
    "affordable_deals[0:130]\n",
    "affordable_deals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a2964",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "yad2_origin = pd.read_csv(\"Data/Real_Estate_TLV_YAD2.csv\",index_col=0)\n",
    "\n",
    "def covert_data(df):\n",
    "    df = df.dropna()\n",
    "    df.loc[:, 'price'] = df['price'].str.replace('[^0-9]','',regex=True).astype(int)\n",
    "    df.loc[:, 'buildingMR'] = df['buildingMR'].astype(int)\n",
    "    df.loc[:, 'floor'] = df['floor'].astype(int)\n",
    "\n",
    "    \n",
    "    df.rename(columns={'price':'DEALAMOUNT'}, inplace=True)\n",
    "    df.rename(columns={'buildingMR':'ASSETMETER'}, inplace=True)\n",
    "    df.rename(columns={'floor':'FLOOR'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "yad2_origin = covert_data(yad2_origin)\n",
    "yad2_origin.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(df1, df2):\n",
    "    new_df = df1.merge(df2, on=['ASSETMETER', 'DEALAMOUNT','FLOOR'], how='right')\n",
    "    new_df = new_df.drop(['TotalFloors','home_number_2','ROOMNUM'], axis=1)\n",
    "    new_df = new_df.dropna()\n",
    "    return new_df\n",
    "\n",
    "yad2_all = merge_dataframes(yad2_origin,affordable_deals)\n",
    "yad2_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yad2_all = yad2_all.reindex(columns=[\"DATE\", \"DEALAMOUNT\", 'PREDICTED_PRICE', 'difference','long_y','lat_y','lat_x', 'long_x'\n",
    "                                    , 'street', 'neighborhood'\n",
    "                                    , 'BUILDINGYEAR', 'BUILDINGFLOORS','home_number', 'item_id',\n",
    "                                     'ASSETMETER', 'TotalFloors', 'asset_classification', 'rooms', 'FLOOR',\n",
    "                                       'shelter', 'on_pillars', 'elevator', 'storeroom','parking', \"Distance_From_Sea\"])\n",
    "\n",
    "yad2_all.sort_values(by=\"difference\",  ascending=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738392c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
