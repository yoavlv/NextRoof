{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60730ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import re\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba763b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5714, 39)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/yad_2_data.csv')\n",
    "def algo_accuracy(df):\n",
    "    df['Accuracy'] = 0\n",
    "    \n",
    "    for row in range(df.shape[0]):\n",
    "        accuracy = 20\n",
    "        \n",
    "        if pd.notna(df.at[row, 'Neighborhood']):\n",
    "            accuracy += 10\n",
    "            \n",
    "        if pd.notna(df.at[row, 'Home_number']):\n",
    "            accuracy += 10\n",
    "            \n",
    "        if df.at[row, 'Long'] != 0:\n",
    "            accuracy += 10\n",
    "            \n",
    "        if df.at[row, 'Lat'] != 0:\n",
    "            accuracy += 10\n",
    "            \n",
    "        if df.at[row, 'Size'] != 0 and pd.notna(df.at[row, 'Size']):\n",
    "            accuracy += 10\n",
    "            \n",
    "        if df.at[row, 'Rooms'] != 0 and pd.notna(df.at[row, 'Rooms']):\n",
    "            accuracy += 10\n",
    "        \n",
    "        if pd.notna(df.at[row, 'Floor']):\n",
    "            accuracy += 10\n",
    "            \n",
    "        if pd.notna(df.at[row, 'Floors']):\n",
    "            accuracy += 10\n",
    "        \n",
    "        df.at[row, 'Accuracy'] = accuracy\n",
    "        \n",
    "    return df\n",
    "\n",
    "def drop_rows_with_keyword(df):\n",
    "    keywords = ['פנטאהוס','בדמי מפתח', 'דמי מפתח', 'משרד', 'לא למגורים','סכסוך',\n",
    "                'משרדים' ,'אולם','מפתח' ,'לשימור','דרוש שיפוץ','דרושה שיפוץ','להריסה','דירת פאר','מחולקת']\n",
    "    df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "    # Generate the conditions for dropping rows\n",
    "    conditions = [df['Text'].str.contains(keyword, case=False) for keyword in keywords]\n",
    "    drop_mask = pd.concat(conditions, axis=1).any(axis=1)\n",
    "\n",
    "    # Drop the rows that meet any of the conditions\n",
    "    df = df[~drop_mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = algo_accuracy(df)\n",
    "df = drop_rows_with_keyword(df) \n",
    "try:\n",
    "    df = df.drop(['level_0', 'index'], axis=1)\n",
    "except:\n",
    "    pass\n",
    "df.to_csv('Data/yad_2_data.csv' ,index=False )\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9557fbb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gush_chelka_api(address):\n",
    "    headers = {\n",
    "        'sec-ch-ua': '\"Not/A)Brand\";v=\"99\", \"Google Chrome\";v=\"115\", \"Chromium\";v=\"115\"',\n",
    "        'auth_data': '{\"api_token\":\"03387185-da2d-4cb4-a3c6-2292a3df7915\",\"user_token\":\"\",\"domain\":\"www.gov.il\",\"token\":\"qMZlz1IwqfKc6WhO6qet3OHGjLusa/tBvtVdRBurehytCsrtnVhcI81jhg/2pDc39ChRLpK7C+mzq4rg5GjqdHfTQJANTYMPAmVWrfMwL4O2AMtdLCq+QEt/inww791B+vWYq7Z0PiAq8lUPSBuB1//YGsM/BvB9daJoQwguhya+2NxIm2JK2gfMp+RnSHzGdn4LFWLuLw3lHHYzhGT8Q8+3vzRbF/vSl79P7qNAoLxGPApgGa80OA==\",\"user_id\":178592,\"isAdmin\":false,\"expires\":\"2023-08-15T21:20:19.0844919+03:00\"}',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "        'Content-Type': 'application/json; charset=UTF-8',\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Referer': 'https://www.gov.il/',\n",
    "        'sec-ch-ua-platform': '\"Windows\"',\n",
    "    }\n",
    "\n",
    "    json_data = {\n",
    "        'type': 0,\n",
    "        'address': address,\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://ags.govmap.gov.il/Api/Controllers/GovmapApi/SearchAndLocate', headers=headers, json=json_data)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['status'] != 0:\n",
    "            return False\n",
    "        if 'data' in data and len(data['data']) > 0 and 'Values' in data['data'][0]:\n",
    "            return [int(value) for value in data['data'][0]['Values']]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7890de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n",
      "746\n",
      "1553\n",
      "shape (1553, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoavl\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "def add_gush_helka_tat(df, city='תל אביב'):\n",
    "    df.loc[:, 'Gush'] = np.nan\n",
    "    df.loc[:, 'Helka'] = np.nan\n",
    "    df.loc[:, 'Tat'] = np.nan\n",
    "\n",
    "    df1_gov = pd.read_csv(\"Data/Real_Estate_TLV_GOVMAPS_1.csv\", index_col=0)\n",
    "    df2_gov = pd.read_csv(\"Data/Real_Estate_TLV_GOVMAPS_2.csv\", index_col=0)\n",
    "    df_gov = pd.merge(df1_gov, df2_gov, how='outer')\n",
    "    df_gov[['Gush', 'Helka', 'Tat']] = df_gov['GUSHHELKATAT'].str.split('-|/', n=2, expand=True).astype(np.int32)\n",
    "    df_gov['Home_number'] = df_gov['ADDRESS'].str.extract('(\\d+)').astype(np.int32)\n",
    "    \n",
    "    # Level 0: Government Maps API\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['Home_number']):\n",
    "            home_number = int(row['Home_number'])\n",
    "            street = row['Street']\n",
    "            \n",
    "            for home_n in range(0,10,2):\n",
    "                home_number = home_number + home_n\n",
    "                address = str(street)+' '+str(home_number)+' '+city\n",
    "                gush_chelka = get_gush_chelka_api(address)\n",
    "                if gush_chelka:\n",
    "                    df.loc[index, 'Gush'] = gush_chelka[0]\n",
    "                    df.loc[index, 'Helka'] = gush_chelka[1]\n",
    "                    break\n",
    "            \n",
    "    # Level 1: Government Maps\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['Home_number']) and pd.isna(row['Gush']):\n",
    "            home_number = row['Home_number']\n",
    "            street = row['Street']\n",
    "\n",
    "            matches = df_gov.loc[\n",
    "                (df_gov['STREENNAME'].str.contains(street)) & (df_gov['Home_number'] == home_number), ['Gush', 'Helka', 'Tat']]\n",
    "\n",
    "            if not matches.empty:\n",
    "                df.loc[index, 'Gush'] = matches['Gush'].values[0]\n",
    "                df.loc[index, 'Helka'] = matches['Helka'].values[0]\n",
    "                df.loc[index, 'Tat'] = matches['Tat'].values[0]\n",
    "\n",
    "    # Level 2: Nadlan Database\n",
    "    print(df['Gush'].notna().sum())\n",
    "    df_nadlan = pd.read_csv(\"Data/Nadlan.csv\")\n",
    "    df_nadlan[['Gush', 'Helka', 'Tat']] = df_nadlan['GUSH'].str.split('-|/', n=2, expand=True).astype(np.int32)\n",
    "    df_nadlan = df_nadlan.drop(columns='GUSH', axis=1)\n",
    "    df_nadlan[['Street', 'Home_number']] = df_nadlan['DISPLAYADRESS'].str.extract('(.+)\\s+(\\d+)')\n",
    "    df_nadlan.dropna(subset=['Home_number'], inplace=True)\n",
    "    df_nadlan['Home_number'] = df_nadlan['Home_number'].astype(np.int32)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['Home_number']) and pd.isna(row['Gush']):\n",
    "            home_number = row['Home_number']\n",
    "            street = row['Street']\n",
    "\n",
    "            matches = df_nadlan.loc[\n",
    "                (df_nadlan['Street'].str.contains(street)) & (df_nadlan['Home_number'] == home_number), ['Gush', 'Helka', 'Tat']]\n",
    "\n",
    "            if not matches.empty:\n",
    "                df.loc[index, 'Gush'] = matches['Gush'].values[0]\n",
    "                df.loc[index, 'Helka'] = matches['Helka'].values[0]\n",
    "                df.loc[index, 'Tat'] = matches['Tat'].values[0]\n",
    "\n",
    "    # Level 3: Addresses\n",
    "    print(df['Gush'].notna().sum())\n",
    "    df_address = pd.read_csv(\"Data/Addresses.csv\")\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['Home_number']):\n",
    "            home_number = row['Home_number']\n",
    "            street = row['Street']\n",
    "\n",
    "            gush = df_address.loc[(df_address['ms_bayit'] == home_number) & (df_address['t_rechov'].str.contains(street)), 'ms_gush']\n",
    "            helka = df_address.loc[(df_address['ms_bayit'] == home_number) & (df_address['t_rechov'].str.contains(street)), 'ms_chelka']\n",
    "\n",
    "            if not gush.empty:\n",
    "                df.at[index, 'Gush'] = gush.iloc[0]\n",
    "            if not helka.empty:\n",
    "                df.at[index, 'Helka'] = helka.iloc[0]\n",
    "\n",
    "            if gush.empty and helka.empty:\n",
    "                street_parts = street.split(' ')\n",
    "                last_part = street_parts[-1]\n",
    "                matching_streets = df_address[df_address['t_rechov'].str.contains(last_part)]\n",
    "                if not matching_streets.empty:\n",
    "                    gush = matching_streets.loc[matching_streets['ms_bayit'] == home_number, 'ms_gush']\n",
    "                    helka = matching_streets.loc[matching_streets['ms_bayit'] == home_number, 'ms_chelka']\n",
    "                    if not gush.empty:\n",
    "                        df.at[index, 'Gush'] = gush.iloc[0]\n",
    "                    if not helka.empty:\n",
    "                        df.at[index, 'Helka'] = helka.iloc[0]\n",
    "\n",
    "    df = df.dropna(subset=['Gush', 'Helka'])\n",
    "    df.loc[:, 'Gush'] = df['Gush'].astype(np.int32)\n",
    "    df.loc[:, 'Helka'] = df['Helka'].astype(np.int32)\n",
    "\n",
    "    print(df['Gush'].notna().sum())\n",
    "    return df\n",
    "\n",
    "df = add_gush_helka_tat(df)\n",
    "print(f'shape {df.shape}')\n",
    "# shape (1637, 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d2a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Balconies','Parking','Balconies','Immediate'\n",
    "                      ,'Ac','Furniture','On_pillars','Elevator','Storeroom','Shelter',\n",
    "                     'Text','Date_of_entry','Images','Handicapped','Floors_text','Agency', 'Garden_size' \n",
    "                      , 'Date_added', 'City_code','City'], axis=1)\n",
    "\n",
    "\n",
    "def update_asset_conditon(df):\n",
    "    '''\n",
    "    My index:\n",
    "    1- new from builder\n",
    "    2 - new \n",
    "    3 - good\n",
    "    4 - after reinovtions \n",
    "    5 - need reinovtions\n",
    "    '''\n",
    "    df.rename(columns = {'Asset_classification':'New'}, inplace = True)\n",
    "    df['New'] = df['New'].astype(np.int32)\n",
    "    df.loc[df['New'] == 2, 'New'] = 4 \n",
    "    df.loc[df['New'] == 6, 'New'] = 2\n",
    "    \n",
    "    # 1 new condtion else 0\n",
    "    df['New'] = df['New'].apply(lambda x: 1 if x in [1, 2] else 0)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def update_neighborhood_street(df):\n",
    "    df['Street'] = df['Street'].str.strip()\n",
    "    old = \"'\"\n",
    "    new = ''\n",
    "    df['Street'] = df['Street'].str.replace(old,new)\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace(old,new)\n",
    "    \n",
    "    old = 'כרמייה'\n",
    "    new = 'כרמיה'\n",
    "    df['Street'] = df['Street'].str.replace(old,new)\n",
    "\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.strip()\n",
    "    old = '-'\n",
    "    new = ' '\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace(old,new)\n",
    "    old = 'נווה אביבים'\n",
    "    new = 'נווה אביבים וסביבתה'\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace(old,new)\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace('לב תל אביב, לב העיר צפון','הצפון הישן החלק הצפוני')\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace('נוה','נווה')\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace('גני צהלה, רמות צהלה','גני צהלה')\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace('נווה אליעזר וכפר שלם מזרח','כפר שלם מזרח נווה אליעזר')\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace('גני שרונה, קרית הממשלה','גני שרונה')\n",
    "    old = 'הצפון הישן   דרום'\n",
    "    new = 'הצפון החדש החלק הדרומי'\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace(old,new)\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.replace('מכללת תל אביב יפו, דקר','דקר')\n",
    "\n",
    "    return df\n",
    " \n",
    "    \n",
    "df = update_asset_conditon(df)\n",
    "df = update_neighborhood_street(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dfc9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coordinates(lat_long_list):\n",
    "    '''\n",
    "    This function use to convert UTM coordinates to ITM coordinates using outside website with selenium \n",
    "    '''\n",
    "    service = Service(\"C:/Users/yoavl/NextRoof/chromedriver_win32/chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get(\"https://zvikabenhaim.appspot.com/software/ITM/\")\n",
    "\n",
    "    # locate all the input fields and button\n",
    "    lat_input = driver.find_element(By.XPATH, '//*[@id=\"lat\"]')\n",
    "    lon_input = driver.find_element(By.XPATH, '//*[@id=\"long\"]')\n",
    "    convert_button = driver.find_element(By.XPATH, '//form[1]/table/tbody/tr[3]/td/input')\n",
    "    east_span = driver.find_element(By.XPATH, '//*[@id=\"itm_east\"]')\n",
    "    north_span = driver.find_element(By.XPATH, '//*[@id=\"itm_north\"]')\n",
    "    \n",
    "    \n",
    "    coverted_list = []\n",
    "    for cords in lat_long_list:\n",
    "        east = cords[0]\n",
    "        north = cords[1]\n",
    "        if cords[0] != 0.0 and cords[1] != 0.0:\n",
    "            lat_input.clear()\n",
    "            lon_input.clear()\n",
    "\n",
    "            # send lat and long to input fields\n",
    "\n",
    "            lat_input.send_keys(cords[0])\n",
    "            lon_input.send_keys(cords[1])\n",
    "\n",
    "            convert_button.click()\n",
    "\n",
    "\n",
    "            east = east_span.text\n",
    "            north = north_span.text\n",
    "            \n",
    "            \n",
    "        coverted_list.append((east,north))\n",
    "        \n",
    "\n",
    "    driver.quit()\n",
    "    return coverted_list\n",
    "\n",
    "def convert_lat_long(df):\n",
    "\n",
    "    def get_long_lat_tuples(df):\n",
    "        long_lat_tuples = []\n",
    "        for index, row in df.iterrows():\n",
    "            lat = row['Lat']\n",
    "            long = row['Long']\n",
    "\n",
    "            try:\n",
    "                lat = float(lat)\n",
    "            except:\n",
    "                lat = 0.0\n",
    "            try:\n",
    "                long = float(long)\n",
    "            except:\n",
    "                long = 0.0  \n",
    "            long_lat_tuples.append((lat, long))\n",
    "        return long_lat_tuples\n",
    "    \n",
    "    new_cord = convert_coordinates(get_long_lat_tuples(df))\n",
    "    \n",
    "    for index, row in df.iterrows():  \n",
    "        try:\n",
    "            df.at[index,'Lat'] = new_cord[index][0]\n",
    "            df.at[index,'Long'] = new_cord[index][1]\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fd7efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1553, 23)\n"
     ]
    }
   ],
   "source": [
    "def find_avg_cords_by_street():\n",
    "    df = pd.read_csv(\"Data/Nadlan_clean.csv\",index_col=0)\n",
    "    df = df.dropna(subset=['Long','Lat','Street']).reset_index(drop=True)\n",
    "    df['Long'] = df['Long'].astype(int)\n",
    "    df['Lat'] = df['Lat'].astype(int)\n",
    "    \n",
    "    # create unique streets list\n",
    "    streets = df['Street'].unique()\n",
    "    \n",
    "    street_cords_avg = {}\n",
    "    for street in streets:\n",
    "        street_df = df[df['Street'] == street]\n",
    "        \n",
    "        lat_mean = street_df['Lat'].mean()\n",
    "        long_mean = street_df['Long'].mean()\n",
    "\n",
    "        street_cords_avg[street] = (long_mean ,lat_mean)\n",
    "        \n",
    "    return street_cords_avg\n",
    "        \n",
    "def complete_long_lat_columns(df,street_cords_avg):\n",
    "    for index, row in df.iterrows():\n",
    "        long = row['Long']\n",
    "        lat = row['Lat']\n",
    "        street = row['Street']\n",
    "        \n",
    "        try:\n",
    "            cords = street_cords_avg[street]         \n",
    "            if long == 0.0 or lat == 0.0:\n",
    "                df.at[index, 'Long'] = cords[1]\n",
    "                df.at[index, 'Lat'] = cords[0]      \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    df.rename(columns = {'Lat':'Temp'}, inplace = True)\n",
    "    df.rename(columns = {'Long':'Lat'}, inplace = True)\n",
    "    df.rename(columns = {'Temp':'Long'}, inplace = True)\n",
    "\n",
    "    df = df.loc[(df['Lat'] != 0.0) & (df['Long'] != 0.0)]\n",
    "    \n",
    "    df.loc[:, 'Long'] = df['Long'].astype(np.int32)\n",
    "    df.loc[:, 'Lat'] = df['Lat'].astype(np.int32)\n",
    "    \n",
    "    return df\n",
    "            \n",
    "# df = convert_lat_long(df)\n",
    "# df =complete_long_lat_columns(df,find_avg_cords_by_street())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44025a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1553, 23)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['Street']).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "#1232 rows × 23 columns\n",
    "\n",
    "\n",
    "# (2464, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2989bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neighborhood():\n",
    "    df = pd.read_csv(\"Data/Real_Estate_TLV_GOVMAPS_1.csv\",index_col=0)\n",
    "    neighborhoods = {}\n",
    "    for index, row in df.iterrows():\n",
    "        neighborhood = row['NEIGHBORHOOD']\n",
    "        street = row['STREENNAME']\n",
    "        if neighborhood not in neighborhoods:\n",
    "            neighborhoods[neighborhood] = set()\n",
    "        neighborhoods[neighborhood].add(street)\n",
    "    return neighborhoods\n",
    "\n",
    "def complete_neighborhood_column(df, neighborhoods):\n",
    "    # Loop through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        street = row['Street']\n",
    "        \n",
    "        # Loop through each neighborhood in the neighborhoods dictionary\n",
    "        for neighborhood, streets in neighborhoods.items():\n",
    "            # Check if the street is in the set of streets for the neighborhood\n",
    "            if street in streets:\n",
    "                # If it is, assign the neighborhood to the 'neighborhood' column for this row\n",
    "                df.at[index, 'Neighborhood'] = neighborhood\n",
    "                break # Break out of the inner loop once we find a match\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = complete_neighborhood_column(df,add_neighborhood())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a583be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_building_year_list():\n",
    "    df = pd.read_csv(\"Data/Nadlan_clean.csv\",index_col=0)\n",
    "    df = df.dropna(subset=['Floors','Street','Build_year']).reset_index(drop=True)\n",
    "    \n",
    "    add_build_year = []\n",
    "    df['Floors'] = df['Floors'].astype(int)\n",
    "    df['Street'] = df['Street'].astype(str)\n",
    "    df['Build_year'] = df['Build_year'].astype(int)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        floors = row['Floors']\n",
    "        street = row['Street']\n",
    "        build_year = row['Build_year']\n",
    "        \n",
    "        build_string = (str(floors)+str(street)+str(build_year)).strip()\n",
    "        \n",
    "        add_build_year.append(build_string)\n",
    "    return list(set(add_build_year))\n",
    "\n",
    "def complete_build_year_column(df, add_build_year):\n",
    "    df['Build_year'] = 0\n",
    "    df['Floors'] = df['Floors'].fillna(0)\n",
    "    \n",
    "    df['Floors'] = df['Floors'].astype(int)\n",
    "    df['Street'] = df['Street'].astype(str)\n",
    "    \n",
    "    # Loop through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        floors = row['Floors']\n",
    "        street = row['Street']\n",
    "        build_year = row['Build_year']\n",
    "\n",
    "        build_string = (str(floors)+str(street)).strip().strip()\n",
    "\n",
    "        for item in add_build_year:\n",
    "            floors_street_year = item.strip()\n",
    "            \n",
    "            if floors_street_year.startswith(build_string):\n",
    "                year = floors_street_year[-4:]\n",
    "                year = re.findall(r'\\d+', year)\n",
    "                year = ''.join(year)\n",
    "                df.at[index,'Build_year'] = year\n",
    "                break\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e4fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avg_building_old_by_street():\n",
    "    df = pd.read_csv(\"Data/Nadlan_clean.csv\",index_col=0)\n",
    "    df = df.dropna(subset=['Build_year','Street']).reset_index(drop=True)\n",
    "    df['Build_year'] = df['Build_year'].astype(int)\n",
    "    df['Street'] = df['Street'].astype(str)\n",
    "    \n",
    "    # create unique streets list\n",
    "    streets = df['Street'].unique()\n",
    "    \n",
    "    street_buildings_avg = {}\n",
    "    for street in streets:\n",
    "        \n",
    "        street_df = df[df['Street'] == street]\n",
    "        street_mean = street_df['Build_year'].mean()\n",
    "        \n",
    "        \n",
    "        street_buildings_avg[street] = street_mean\n",
    "        \n",
    "    return street_buildings_avg\n",
    "        \n",
    "def complete_building_old_by_street(df,avg_bulding_old_street):\n",
    "    for index, row in df.iterrows():\n",
    "        old = row['Build_year']\n",
    "        street = row['Street']\n",
    "        if old == 0:\n",
    "            try:\n",
    "                avg = avg_bulding_old_street[street] \n",
    "                df.at[index, 'Build_year'] = avg\n",
    "            except:\n",
    "                df.drop(index = index , inplace =True)\n",
    "            \n",
    "            \n",
    "        \n",
    "    df['Build_year'] = df['Build_year'].astype(np.int32)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = complete_build_year_column(df,create_building_year_list())\n",
    "df = complete_building_old_by_street(df,find_avg_building_old_by_street())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e5289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance_from_the_see_TLV(X_coordinate, Y_coordinate):\n",
    "    north_x = 180471\n",
    "    north_y = 672391\n",
    "    south_x = 177333\n",
    "    south_y = 663016\n",
    "    \n",
    "    m = (south_y - north_y) / (south_x - north_x)   \n",
    "    b = north_y - (m * north_x)\n",
    "    \n",
    "    numerator = abs(m * X_coordinate - Y_coordinate + b)\n",
    "    denominator = math.sqrt(m**2 + 1)\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def calc_distance_from_train_station(df):\n",
    "    stations = [(179820.47,662424.54), (180619,664469.56), (181101.44,665688.78), (181710.96,667877.05)]\n",
    "    distances = []\n",
    "\n",
    "     # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        apartment_coords = (row['Lat'], row['Long'])\n",
    "\n",
    "        # Calculate the distance between the apartment and each train station\n",
    "        station_distances = []\n",
    "        for station_coords in stations:       \n",
    "            station_distance = abs(station_coords[0] - apartment_coords[1]) + abs(station_coords[1] - apartment_coords[0])\n",
    "            station_distances.append(station_distance)\n",
    "\n",
    "        # Find the minimum distance\n",
    "        min_distance = min(station_distances)\n",
    "        distances.append(min_distance)\n",
    "\n",
    "    df['Train'] = distances\n",
    "    df['Train'] = df['Train'].astype(np.int32)\n",
    "    return df\n",
    "    \n",
    "def distance_from_sea_tlv(df):\n",
    "    '''\n",
    "    Need to fix long ? lat ? \n",
    "    '''\n",
    "    df = df.dropna(subset=['Lat', 'Long']).reset_index(drop=True)\n",
    "    latitudes = df['Long'].astype(float)\n",
    "    longitudes = df['Lat'].astype(float)\n",
    "    distances = [calc_distance_from_the_see_TLV(lat, lon) for lat, lon in zip(latitudes, longitudes)]\n",
    "    df['Distance_sea'] = distances\n",
    "    df['Distance_sea'] = df['Distance_sea'].astype(np.int32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8feac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_parking(df):\n",
    "    # Not in use\n",
    "    df['Parking'] = df['Parking'].str.replace('ללא','0')\n",
    "    df['Parking'] = df['Parking'].astype(np.int32)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def add_date(df):\n",
    "    current_year = datetime.now().year\n",
    "    df['Year'] = current_year\n",
    "    df.assign(profit='NAN')\n",
    "    df['Year'].astype(np.int32)\n",
    "    return df\n",
    "\n",
    "def convert_price(df):\n",
    "    df['Price'] = df['Price'].str.replace('לא צוין מחיר', '0')\n",
    "    df['Price'] = df['Price'].str.replace('₪', '')\n",
    "    df['Price'] = df['Price'].str.replace(',', '')\n",
    "    df['Price'] = df['Price'].astype(np.int32)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def street_and_neighborhood_rank(df, column):\n",
    "    df = update_neighborhood_street(df)\n",
    "    df = df.dropna(subset=['Neighborhood','Street']).reset_index(drop=True)\n",
    "    df_nadlan = pd.read_csv('Data/Nadlan_clean.csv', index_col=0)\n",
    "\n",
    "        \n",
    "    streets_rank = {}\n",
    "    years = df_nadlan['Year'].unique()\n",
    "\n",
    "    for year in years:\n",
    "        df_by_year = df_nadlan[df_nadlan['Year'] == year]\n",
    "        streets_rank[year] = {}\n",
    "\n",
    "        for item in df_by_year[column].unique():\n",
    "            df_by_item = df_by_year[df_by_year[column] == item]  # Filter df by item\n",
    "            \n",
    "            item_year_rank = np.nan\n",
    "            if df_by_item['Size'].sum() != 0:\n",
    "                item_year_rank = df_by_item['Price'].sum() / df_by_item['Size'].sum()\n",
    "\n",
    "            streets_rank[year][item] = item_year_rank\n",
    "\n",
    "    new_column_name = column + '_rank'\n",
    "    df[new_column_name] = np.nan\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        year = row['Year']\n",
    "        item = row[column]\n",
    "        found_street = False\n",
    "\n",
    "        # Check for exact matches\n",
    "        for nadlan_street in df_nadlan[column].unique():\n",
    "            if item == nadlan_street:\n",
    "                found_street = True\n",
    "                item = nadlan_street\n",
    "                break\n",
    "\n",
    "        # Check for partial matches\n",
    "        if not found_street and  found_street != False:\n",
    "            for nadlan_street in df_nadlan[column].unique():\n",
    "                if item in nadlan_street:\n",
    "                    item = nadlan_street\n",
    "                    found_street = True\n",
    "                    break\n",
    "                    \n",
    "                check_parts = nadlan_street.split(' ')\n",
    "                print(check_parts)\n",
    "                if item in check_parts:\n",
    "                    item = nadlan_street\n",
    "                    found_street = True\n",
    "                    break\n",
    "\n",
    "        if found_street:\n",
    "            for potential_year in [year, year-1, year-2 , year-3]:\n",
    "                try:\n",
    "                    df.at[index, new_column_name] = streets_rank[potential_year][item]\n",
    "                    break\n",
    "                except KeyError:\n",
    "                    continue               \n",
    "        else:\n",
    "            pass\n",
    "#             print(f\"Could not find a match for {column} '{item}'\")\n",
    "            \n",
    "    mean = df[new_column_name].mean()\n",
    "    df[new_column_name] = df[new_column_name].fillna(mean)\n",
    "    df[new_column_name] = df[new_column_name].astype(np.int32)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e3021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_price(df)\n",
    "# df = distance_from_sea_tlv(df)\n",
    "# df = calc_distance_from_train_station(df)\n",
    "df = add_date(df)\n",
    "df = street_and_neighborhood_rank(df,'Neighborhood')\n",
    "df = street_and_neighborhood_rank(df,'Street')\n",
    "df = street_and_neighborhood_rank(df,'Gush')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b4fb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_match(df_nadlan, helka, year):\n",
    "    helka = int(helka)\n",
    "    helka_offsets = [helka - 1, helka + 1, helka + 2, helka - 2, helka + 3, helka - 3, helka + 4, helka - 4]\n",
    "    for helka_offset in helka_offsets:\n",
    "        for year_offset in range(4, 0, -1):\n",
    "            year_temp = year - year_offset\n",
    "            match = df_nadlan.loc[(df_nadlan['Gush_Helka'] == str(helka_offset)) & (df_nadlan['Year'] == year_temp), 'Helka_rank']\n",
    "            if not match.empty:\n",
    "                return match\n",
    "    return match\n",
    "\n",
    "\n",
    "def helka_rank(df):\n",
    "    count = 0\n",
    "    df = df.dropna(subset=['Gush','Helka']).reset_index(drop=True)\n",
    "    df_nadlan = pd.read_csv('Data/Nadlan_clean.csv', index_col=0)\n",
    "    df_nadlan['Gush_Helka'] = df_nadlan['Gush'].astype(str) + df_nadlan['Helka'].astype(str)\n",
    "    \n",
    "    column = 'Gush_Helka'\n",
    "\n",
    "    df[column] = df['Gush'].astype(str) + df['Helka'].astype(str)\n",
    "    df[column] = df[column].str.replace('.','')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gush_helka = row['Gush_Helka']\n",
    "        current_year = datetime.now().year\n",
    "        year = current_year\n",
    "        helka_rank = np.nan\n",
    "        \n",
    "        match = df_nadlan.loc[(df_nadlan['Gush_Helka'] == gush_helka) & df_nadlan['Year'] == year  ,'Helka_rank']\n",
    "        \n",
    "        if match.empty:\n",
    "            match = check_for_match(df_nadlan, gush_helka , year)\n",
    "    \n",
    "        \n",
    "        if not match.empty:\n",
    "            df.at[index, 'Helka_rank'] = match.values[0]\n",
    "        \n",
    "        if match.empty:\n",
    "            count+=1\n",
    "    mean = df['Helka_rank'].mean()\n",
    "    df['Helka_rank'] = df['Helka_rank'].fillna(mean)\n",
    "    df['Helka_rank'] = df['Helka_rank'].astype(np.int32)\n",
    "    print(count)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def check_for_match_update(df_nadlan, helka):\n",
    "    helka = int(helka)\n",
    "    helka_offsets = [helka - 1, helka + 1, helka + 2, helka - 2, helka + 3, helka - 3, helka + 4, helka - 4]\n",
    "    for helka_offset in helka_offsets:\n",
    "        match = df_nadlan.loc[(df_nadlan['Gush_Helka'] == str(helka_offset)), 'Helka_rank']\n",
    "        if not match.empty:\n",
    "            return match\n",
    "    return match\n",
    "\n",
    "def helka_rank_update(df):\n",
    "    count = 0\n",
    "    df = df.dropna(subset=['Gush','Helka']).reset_index(drop=True)\n",
    "    df_nadlan = pd.read_csv('Data/Nadlan_clean.csv', index_col=0)\n",
    "    df_nadlan['Gush_Helka'] = df_nadlan['Gush'].astype(str) + df_nadlan['Helka'].astype(str)\n",
    "    \n",
    "    column = 'Gush_Helka'\n",
    "\n",
    "    df[column] = df['Gush'].astype(str) + df['Helka'].astype(str)\n",
    "    df[column] = df[column].str.replace('.', '', regex=False)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gush_helka = row['Gush_Helka']\n",
    "        helka_rank = np.nan\n",
    "        \n",
    "        match = df_nadlan.loc[(df_nadlan['Gush_Helka'] == gush_helka),'Helka_rank']\n",
    "        \n",
    "        if match.empty:\n",
    "            match = check_for_match_update(df_nadlan, gush_helka)\n",
    "    \n",
    "        if not match.empty:\n",
    "            df.at[index, 'Helka_rank'] = match.values[0]\n",
    "        \n",
    "        if match.empty:\n",
    "            count+=1\n",
    "      \n",
    "    mean = df['Helka_rank'].mean()\n",
    "    df['Helka_rank'] = df['Helka_rank'].fillna(mean)\n",
    "    df['Helka_rank'] = df['Helka_rank'].astype(np.int32)\n",
    "    print(count)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74a6ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "df = helka_rank_update(df)\n",
    "df.to_csv('Data/Yad2_clean.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28a8f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message appended to the file successfully!\n"
     ]
    }
   ],
   "source": [
    "def append_to_file():\n",
    "    file_path = \"status.txt\"\n",
    "    message = \"yad_2_clean pass-success\"\n",
    "\n",
    "    try:\n",
    "        # Open the file in append mode\n",
    "        with open(file_path, \"a\") as file:\n",
    "            # Append the message on a new line\n",
    "            file.write(\"\\n\" + message)\n",
    "\n",
    "        print(\"Message appended to the file successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while appending to the file:\", str(e))\n",
    "\n",
    "# Call the function to append to the file\n",
    "append_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1494258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
